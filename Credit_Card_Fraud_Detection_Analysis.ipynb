{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imperialHCE/theprojects/blob/master/Credit_Card_Fraud_Detection_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJ2KqXTYkX0A"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.under_sampling import NearMiss\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "_TRMPiSZD57e",
        "outputId": "02c59281-81a8-4336-9a80-d8de25c4413d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-21d5c826-8deb-4986-888b-fb66bbe73ff7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-21d5c826-8deb-4986-888b-fb66bbe73ff7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving creditcard.csv to creditcard.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59oeYh8ghDPb"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "df = pd.read_csv(io.BytesIO(uploaded['creditcard.csv']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "G2mTZwS7hGTk",
        "outputId": "89e8f0df-f80b-4e4f-cd31-b14c3c44df4f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-597c4b06-df50-44fc-909f-f03b4499bdd5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>...</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Class</th>\n",
              "      <th>scaled_amount</th>\n",
              "      <th>scaled_time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>...</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>0</td>\n",
              "      <td>1.783274</td>\n",
              "      <td>-0.994983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.269825</td>\n",
              "      <td>-0.994983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>...</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>0</td>\n",
              "      <td>4.983721</td>\n",
              "      <td>-0.994972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>...</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>0</td>\n",
              "      <td>1.418291</td>\n",
              "      <td>-0.994972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>...</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>0</td>\n",
              "      <td>0.670579</td>\n",
              "      <td>-0.994960</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-597c4b06-df50-44fc-909f-f03b4499bdd5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-597c4b06-df50-44fc-909f-f03b4499bdd5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-597c4b06-df50-44fc-909f-f03b4499bdd5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
              "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
              "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
              "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
              "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
              "\n",
              "         V8        V9       V10  ...       V22       V23       V24       V25  \\\n",
              "0  0.098698  0.363787  0.090794  ...  0.277838 -0.110474  0.066928  0.128539   \n",
              "1  0.085102 -0.255425 -0.166974  ... -0.638672  0.101288 -0.339846  0.167170   \n",
              "2  0.247676 -1.514654  0.207643  ...  0.771679  0.909412 -0.689281 -0.327642   \n",
              "3  0.377436 -1.387024 -0.054952  ...  0.005274 -0.190321 -1.175575  0.647376   \n",
              "4 -0.270533  0.817739  0.753074  ...  0.798278 -0.137458  0.141267 -0.206010   \n",
              "\n",
              "        V26       V27       V28  Class  scaled_amount  scaled_time  \n",
              "0 -0.189115  0.133558 -0.021053      0       1.783274    -0.994983  \n",
              "1  0.125895 -0.008983  0.014724      0      -0.269825    -0.994983  \n",
              "2 -0.139097 -0.055353 -0.059752      0       4.983721    -0.994972  \n",
              "3 -0.221929  0.062723  0.061458      0       1.418291    -0.994972  \n",
              "4  0.502292  0.219422  0.215153      0       0.670579    -0.994960  \n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lP7VzgD9haLQ"
      },
      "source": [
        "Feature Scalling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "qyMELrEMhU-f",
        "outputId": "01d61b22-71e1-44cd-ccaa-31f3bbec97bd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-728096f8-2971-437e-90c2-58aa595a864b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>...</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Class</th>\n",
              "      <th>scaled_amount</th>\n",
              "      <th>scaled_time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>...</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>0</td>\n",
              "      <td>1.783274</td>\n",
              "      <td>-0.994983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.269825</td>\n",
              "      <td>-0.994983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>...</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>0</td>\n",
              "      <td>4.983721</td>\n",
              "      <td>-0.994972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>...</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>0</td>\n",
              "      <td>1.418291</td>\n",
              "      <td>-0.994972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>...</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>0</td>\n",
              "      <td>0.670579</td>\n",
              "      <td>-0.994960</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-728096f8-2971-437e-90c2-58aa595a864b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-728096f8-2971-437e-90c2-58aa595a864b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-728096f8-2971-437e-90c2-58aa595a864b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
              "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
              "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
              "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
              "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
              "\n",
              "         V8        V9       V10  ...       V22       V23       V24       V25  \\\n",
              "0  0.098698  0.363787  0.090794  ...  0.277838 -0.110474  0.066928  0.128539   \n",
              "1  0.085102 -0.255425 -0.166974  ... -0.638672  0.101288 -0.339846  0.167170   \n",
              "2  0.247676 -1.514654  0.207643  ...  0.771679  0.909412 -0.689281 -0.327642   \n",
              "3  0.377436 -1.387024 -0.054952  ...  0.005274 -0.190321 -1.175575  0.647376   \n",
              "4 -0.270533  0.817739  0.753074  ...  0.798278 -0.137458  0.141267 -0.206010   \n",
              "\n",
              "        V26       V27       V28  Class  scaled_amount  scaled_time  \n",
              "0 -0.189115  0.133558 -0.021053      0       1.783274    -0.994983  \n",
              "1  0.125895 -0.008983  0.014724      0      -0.269825    -0.994983  \n",
              "2 -0.139097 -0.055353 -0.059752      0       4.983721    -0.994972  \n",
              "3 -0.221929  0.062723  0.061458      0       1.418291    -0.994972  \n",
              "4  0.502292  0.219422  0.215153      0       0.670579    -0.994960  \n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#RobustScaler is less prone to outliers\n",
        "std_scaler = StandardScaler()\n",
        "rob_scaler = RobustScaler()\n",
        "df['scaled_amount'] = rob_scaler.fit_transform(df['Amount'].values.reshape(-1,1))\n",
        "df['scaled_time'] = rob_scaler.fit_transform(df['Time'].values.reshape(-1,1))\n",
        "df.drop(['Time', 'Amount'], axis = 1, inplace=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "1JEIawkPhiJo",
        "outputId": "6072610b-3f41-4db5-9f01-14c5638c9fb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classes Count in Credit Card Fruad Dataset \n",
            " 0    284315\n",
            "1       492\n",
            "Name: Class, dtype: int64\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Frequency')"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Imbalanced Classes\n",
        "\n",
        "\n",
        "print(f'Classes Count in Credit Card Fruad Dataset \\n', pd.value_counts(df['Class'], sort = True).sort_index())\n",
        "credit_classes = pd.value_counts(df['Class'], sort = True).sort_index()\n",
        "credit_classes.plot(kind = 'bar')\n",
        "plt.title('Fraud class histogram')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Frequency')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-Z5KqyuhsPN",
        "outputId": "d8d29704-17f6-4800-e467-eef74dba5882"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'scaled_amount', 'scaled_time']\n"
          ]
        }
      ],
      "source": [
        "#Creating independent and dependent features\n",
        "\n",
        "columns = df.columns.tolist()\n",
        "\n",
        "#Filter the Columns\n",
        "\n",
        "columns = [c for c in columns if c not in ['Class']]\n",
        "print(columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b8MGUYthwYb",
        "outputId": "a77d31b3-90a5-400c-e7de-d75b8ef90c17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(284807, 30)\n",
            "(284807,)\n"
          ]
        }
      ],
      "source": [
        "#Store the variable we are predicting\n",
        "\n",
        "target = 'Class'\n",
        "\n",
        "#define X and Y df\n",
        "\n",
        "X =  df[columns]\n",
        "Y = df[target]\n",
        "\n",
        "print(X.shape)\n",
        "print(Y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3R7cyyC0hz2A",
        "outputId": "5ac1df94-422b-4f88-9735-ee46979ba790"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resampled dataset shape Counter({0: 492, 1: 492})\n"
          ]
        }
      ],
      "source": [
        "#Undersampling\n",
        "nm = RandomUnderSampler(random_state=42)\n",
        "X_us, y_us = nm.fit_resample(X,Y)\n",
        "X_train_us, X_test_us, y_train_us, y_test_us = train_test_split(X_us, y_us, test_size = 0.2)\n",
        "from collections import Counter\n",
        "print('Resampled dataset shape %s' % Counter(y_us))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTac4Jh_h4xF"
      },
      "outputs": [],
      "source": [
        "# Oversampling\n",
        "from imblearn.over_sampling import SMOTE\n",
        "os = SMOTE(sampling_strategy=1)\n",
        "X_os, y_os = os.fit_resample(X,Y)\n",
        "X_train_os, X_test_os, y_train_os, y_test_os = train_test_split(X_os, y_os, test_size = 0.2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkVBHLqQiegi"
      },
      "source": [
        "Now we will be looking at what metrics are well suitable for the credit card fraud detection problem and will try to work on a few supervised machine learning models and perform hyper tuning to get the best results.\n",
        "\n",
        "Choosing the Right Metrics for Model\n",
        "As the analysis is focused on credit card fraud detection, we will evaluate the performance of the Model based on few metrics listed below:\n",
        "\n",
        "Confusion Matrix\n",
        "\n",
        "Accuracy, Recall, Precision and F1-Score\n",
        "\n",
        "ROC Curve and AUC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7ZaM23zihBQ",
        "outputId": "9c89e87e-4162-4edf-babd-7c3144c80e3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 540 candidates, totalling 1620 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "540 fits failed out of a total of 1620.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "180 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "180 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "180 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 464, in _check_solver\n",
            "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
            "ValueError: penalty='none' is not supported for the liblinear solver\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.88055709 0.88055709 0.83733879        nan        nan 0.51461411\n",
            " 0.9250283  0.94280614        nan 0.88055709 0.88055709 0.83733879\n",
            "        nan        nan 0.51461411 0.94280614 0.94280614        nan\n",
            " 0.88055709 0.88055709 0.83733879        nan        nan 0.51461411\n",
            " 0.94280614 0.94280614        nan 0.89071102 0.89071102 0.86273571\n",
            "        nan        nan 0.51461411 0.9250283  0.94280614        nan\n",
            " 0.89071102 0.89071102 0.86273571        nan        nan 0.51461411\n",
            " 0.94280614 0.94280614        nan 0.89071102 0.89071102 0.86273571\n",
            "        nan        nan 0.51461411 0.94280614 0.94280614        nan\n",
            " 0.90342883 0.90342883 0.8830871         nan        nan 0.51461411\n",
            " 0.9250283  0.94280614        nan 0.90342883 0.90342883 0.8830871\n",
            "        nan        nan 0.51461411 0.94280614 0.94280614        nan\n",
            " 0.90342883 0.90342883 0.8830871         nan        nan 0.51461411\n",
            " 0.94280614 0.94280614        nan 0.91486953 0.91486953 0.91231533\n",
            "        nan        nan 0.74076762 0.9250283  0.94280614        nan\n",
            " 0.91486953 0.91486953 0.91231533        nan        nan 0.74076762\n",
            " 0.94280614 0.94280614        nan 0.91486953 0.91486953 0.91231533\n",
            "        nan        nan 0.74076762 0.94280614 0.94280614        nan\n",
            " 0.92631024 0.92631024 0.92120667        nan        nan 0.74585184\n",
            " 0.9250283  0.94280614        nan 0.92631024 0.92631024 0.92120667\n",
            "        nan        nan 0.74585184 0.94280614 0.94280614        nan\n",
            " 0.92631024 0.92631024 0.92120667        nan        nan 0.74585184\n",
            " 0.94280614 0.94280614        nan 0.93011736 0.93011736 0.93390513\n",
            "        nan        nan 0.91231533 0.9250283  0.94280614        nan\n",
            " 0.93011736 0.93011736 0.93390513        nan        nan 0.91358759\n",
            " 0.94280614 0.94280614        nan 0.93011736 0.93011736 0.93390513\n",
            "        nan        nan 0.91358759 0.94280614 0.94280614        nan\n",
            " 0.93138479 0.93138479 0.92755348        nan        nan 0.93010768\n",
            " 0.9250283  0.94280614        nan 0.93138479 0.93138479 0.92755348\n",
            "        nan        nan 0.93010768 0.94280614 0.94280614        nan\n",
            " 0.93138479 0.93138479 0.92755348        nan        nan 0.93010768\n",
            " 0.94280614 0.94280614        nan 0.92883058 0.92883058 0.92754864\n",
            "        nan        nan 0.93265705 0.9250283  0.94280614        nan\n",
            " 0.92883058 0.92883058 0.92754864        nan        nan 0.93265705\n",
            " 0.94280614 0.94280614        nan 0.92883058 0.92883058 0.92754864\n",
            "        nan        nan 0.93265705 0.94280614 0.94280614        nan\n",
            " 0.93136544 0.93136544 0.92754864        nan        nan 0.93518707\n",
            " 0.9250283  0.94280614        nan 0.93136544 0.93136544 0.92754864\n",
            "        nan        nan 0.93518707 0.94280614 0.94280614        nan\n",
            " 0.93136544 0.93136544 0.92754864        nan        nan 0.93518707\n",
            " 0.94280614 0.94280614        nan 0.92882091 0.92882091 0.92882091\n",
            "        nan        nan 0.93009317 0.9250283  0.94280614        nan\n",
            " 0.92882091 0.92882091 0.92882091        nan        nan 0.93009317\n",
            " 0.94280614 0.94280614        nan 0.92882091 0.92882091 0.92882091\n",
            "        nan        nan 0.93009317 0.94280614 0.94280614        nan\n",
            " 0.92755348 0.92755348 0.92882574        nan        nan 0.92501862\n",
            " 0.9250283  0.94280614        nan 0.92755348 0.92755348 0.92882574\n",
            "        nan        nan 0.92501862 0.94280614 0.94280614        nan\n",
            " 0.92755348 0.92755348 0.92882574        nan        nan 0.92501862\n",
            " 0.94280614 0.94280614        nan 0.92374636 0.92374636 0.9224741\n",
            "        nan        nan 0.92501862 0.9250283  0.94280614        nan\n",
            " 0.92374636 0.92374636 0.9224741         nan        nan 0.92501862\n",
            " 0.94280614 0.94280614        nan 0.92374636 0.92374636 0.9224741\n",
            "        nan        nan 0.92501862 0.94280614 0.94280614        nan\n",
            " 0.92755832 0.92755832 0.92628605        nan        nan 0.92755832\n",
            " 0.9250283  0.94280614        nan 0.92755832 0.92755832 0.92628605\n",
            "        nan        nan 0.92883058 0.94280614 0.94280614        nan\n",
            " 0.92755832 0.92755832 0.92628605        nan        nan 0.92883058\n",
            " 0.94280614 0.94280614        nan 0.92883058 0.92883058 0.92755832\n",
            "        nan        nan 0.92755832 0.9250283  0.94280614        nan\n",
            " 0.92883058 0.92883058 0.92755832        nan        nan 0.92883058\n",
            " 0.94280614 0.94280614        nan 0.92883058 0.92883058 0.92755832\n",
            "        nan        nan 0.92883058 0.94280614 0.94280614        nan\n",
            " 0.93137995 0.93137995 0.93010768        nan        nan 0.92883542\n",
            " 0.9250283  0.94280614        nan 0.93137995 0.93137995 0.93010768\n",
            "        nan        nan 0.93010768 0.94280614 0.94280614        nan\n",
            " 0.93137995 0.93137995 0.93010768        nan        nan 0.92883542\n",
            " 0.94280614 0.94280614        nan 0.93010768 0.93010768 0.93010768\n",
            "        nan        nan 0.92756315 0.9250283  0.94280614        nan\n",
            " 0.93010768 0.93010768 0.93010768        nan        nan 0.92756315\n",
            " 0.94280614 0.94280614        nan 0.93010768 0.93010768 0.93010768\n",
            "        nan        nan 0.92756315 0.94280614 0.94280614        nan\n",
            " 0.92884026 0.93010768 0.93010768        nan        nan 0.92883542\n",
            " 0.9250283  0.94280614        nan 0.93010768 0.93010768 0.93010768\n",
            "        nan        nan 0.92883542 0.94280614 0.94280614        nan\n",
            " 0.93010768 0.93010768 0.93010768        nan        nan 0.92883542\n",
            " 0.94280614 0.94280614        nan 0.93011252 0.93392448 0.92883542\n",
            "        nan        nan 0.93010768 0.9250283  0.94280614        nan\n",
            " 0.93392448 0.93392448 0.92883542        nan        nan 0.92883542\n",
            " 0.94280614 0.94280614        nan 0.93392448 0.93392448 0.92883542\n",
            "        nan        nan 0.93010768 0.94280614 0.94280614        nan\n",
            " 0.92629573 0.9351919  0.93392448        nan        nan 0.93010768\n",
            " 0.9250283  0.94280614        nan 0.9351919  0.9351919  0.93392448\n",
            "        nan        nan 0.93010768 0.94280614 0.94280614        nan\n",
            " 0.9351919  0.9351919  0.93392448        nan        nan 0.93010768\n",
            " 0.94280614 0.94280614        nan 0.92629573 0.93899902 0.93010285\n",
            "        nan        nan 0.93010768 0.9250283  0.94280614        nan\n",
            " 0.93899902 0.93899902 0.93010285        nan        nan 0.93010768\n",
            " 0.94280614 0.94280614        nan 0.93899902 0.93899902 0.93010285\n",
            "        nan        nan 0.93010768 0.94280614 0.94280614        nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "LogisticRegression(C=0.0001, penalty='none', solver='newton-cg')"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "logmodel= LogisticRegression()\n",
        "\n",
        "param_grid = [\n",
        "    {'penalty' : ['l2', 'l1', 'none'],\n",
        "    'C' : np.logspace(-4, 4, 20),\n",
        "    'solver' : ['lbfgs','newton-cg','liblinear'],\n",
        "    'max_iter' : [100, 1000, 2500]\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "logcls_us = GridSearchCV(logmodel, param_grid = param_grid, cv = 3, verbose=True, n_jobs=-1)\n",
        "bestlogcls_us = logcls_us.fit(X_train_us, y_train_us)\n",
        "bestlogcls_us.best_estimator_\n",
        "print(f'Accuracy - : {bestlogcls_us.score(X_train_us, y_train_us):.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wm6oGAAvixwu",
        "outputId": "0febbfdd-a801-4165-a3a8-c01d16acbd37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            " [[ 85   2]\n",
            " [  5 105]]\n",
            "\n",
            " Recall: 0.9545454545454546\n",
            "\n",
            " Accuracy Score: 0.9644670050761421\n",
            "\n",
            " Precision Score: 0.9813084112149533\n",
            "\n",
            " F1 Score: 0.967741935483871\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, classification_report, roc_curve, auc\n",
        "def model_performance(y_test, y_pred):\n",
        "  print(f'Confusion Matrix:\\n',confusion_matrix(y_test, y_pred))\n",
        "  print(f'\\n Recall:', recall_score(y_test, y_pred))\n",
        "  print(f'\\n Accuracy Score:', accuracy_score(y_test, y_pred))\n",
        "  print(f'\\n Precision Score:', precision_score(y_test, y_pred))\n",
        "  print(f'\\n F1 Score:' ,f1_score(y_test, y_pred))\n",
        "  roc_curve(y_test, y_pred, pos_label=True)\n",
        "  return\n",
        "\n",
        "\n",
        "predict_us = bestlogcls_us.predict(X_test_us)\n",
        "model_performance(y_test_us,predict_us)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-00-8EXjSAz"
      },
      "source": [
        "As per as model performance, we received a recall score of 90%. Which states that 90% of the total Fraud transaction is correctly predicted by the classification model. The Accuracy score we got is 93%\n",
        "\n",
        "Now let’s perform Logistic Regression on Over-Sampled Data and look at its performance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "w39bkhQvjX4s",
        "outputId": "e18b3d01-abf4-4329-c0be-b723c79c0c31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 360 candidates, totalling 1080 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "360 fits failed out of a total of 1080.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "120 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "120 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "120 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 464, in _check_solver\n",
            "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
            "ValueError: penalty='none' is not supported for the liblinear solver\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.93444331 0.93994557 0.93994337 0.94179871\n",
            " 0.94867269 0.94867049        nan        nan        nan 0.9344587\n",
            " 0.93994557 0.93994337 0.94179871 0.94867269 0.94867049        nan\n",
            "        nan        nan 0.93721752 0.94249996 0.94250216 0.94324517\n",
            " 0.94867269 0.94867049        nan        nan        nan 0.93717356\n",
            " 0.94249996 0.94250216 0.94324517 0.94867269 0.94867049        nan\n",
            "        nan        nan 0.94073255 0.9442234  0.9442234  0.94427176\n",
            " 0.94867269 0.94867049        nan        nan        nan 0.94072376\n",
            " 0.9442234  0.9442234  0.94427176 0.94867269 0.94867049        nan\n",
            "        nan        nan 0.94400577 0.94531593 0.94531813 0.94550279\n",
            " 0.94867269 0.94867049        nan        nan        nan 0.94400797\n",
            " 0.94531593 0.94531813 0.94550279 0.94867269 0.94867049        nan\n",
            "        nan        nan 0.94567205 0.94689429 0.94689429 0.9466217\n",
            " 0.94867269 0.94867049        nan        nan        nan 0.94566766\n",
            " 0.94689429 0.94689429 0.9466217  0.94867269 0.94867049        nan\n",
            "        nan        nan 0.94704377 0.94758455 0.94758235 0.94745485\n",
            " 0.94867269 0.94867049        nan        nan        nan 0.94707894\n",
            " 0.94758455 0.94758235 0.94745485 0.94867269 0.94867049        nan\n",
            "        nan        nan 0.94783515 0.94819566 0.94819786 0.94807696\n",
            " 0.94867269 0.94867049        nan        nan        nan 0.94783295\n",
            " 0.94819566 0.94819786 0.94807696 0.94867269 0.94867049        nan\n",
            "        nan        nan 0.9481517  0.94849902 0.94849902 0.94846605\n",
            " 0.94867269 0.94867049        nan        nan        nan 0.94808795\n",
            " 0.94849902 0.94849902 0.94846605 0.94867269 0.94867049        nan\n",
            "        nan        nan 0.94834954 0.94861114 0.94861114 0.94860014\n",
            " 0.94867269 0.94867049        nan        nan        nan 0.94822864\n",
            " 0.94861114 0.94861114 0.94860014 0.94867269 0.94867049        nan\n",
            "        nan        nan 0.94835614 0.94863751 0.94864191 0.94863092\n",
            " 0.94867269 0.94867049        nan        nan        nan 0.94842428\n",
            " 0.94863751 0.94864191 0.94863092 0.94867269 0.94867049        nan\n",
            "        nan        nan 0.94834295 0.9486617  0.9486595  0.94864411\n",
            " 0.94867269 0.94867049        nan        nan        nan 0.94846825\n",
            " 0.9486573  0.9486595  0.94864411 0.94867269 0.94867049        nan\n",
            "        nan        nan 0.94838691 0.9486617  0.94866609 0.9486617\n",
            " 0.94867269 0.94867049        nan        nan        nan 0.94847924\n",
            " 0.9486617  0.94866609 0.9486617  0.94867269 0.94867049        nan\n",
            "        nan        nan 0.94838911 0.94867049 0.94866829 0.9486551\n",
            " 0.94867269 0.94867049        nan        nan        nan 0.94848583\n",
            " 0.94867049 0.94866829 0.9486551  0.94867269 0.94867049        nan\n",
            "        nan        nan 0.94848583 0.94867049 0.94867049 0.9486529\n",
            " 0.94867269 0.94867049        nan        nan        nan 0.94834734\n",
            " 0.94867049 0.94867049 0.9486529  0.94867269 0.94867049        nan\n",
            "        nan        nan 0.94844846 0.94867708 0.94867049 0.9486529\n",
            " 0.94867269 0.94867049        nan        nan        nan 0.94844187\n",
            " 0.94867488 0.94867049 0.9486529  0.94867269 0.94867049        nan\n",
            "        nan        nan 0.94837592 0.94867269 0.94867049 0.9486529\n",
            " 0.94867269 0.94867049        nan        nan        nan 0.94845945\n",
            " 0.94867269 0.94867049 0.9486529  0.94867269 0.94867049        nan\n",
            "        nan        nan 0.94856937 0.94867269 0.94867049 0.9486529\n",
            " 0.94867269 0.94867049        nan        nan        nan 0.94844846\n",
            " 0.94867269 0.94867049 0.9486529  0.94867269 0.94867049        nan\n",
            "        nan        nan 0.94843308 0.94867488 0.94867049 0.9486529\n",
            " 0.94867269 0.94867049        nan        nan        nan 0.94857596\n",
            " 0.94867488 0.94867049 0.9486529  0.94867269 0.94867049        nan\n",
            "        nan        nan 0.94843088 0.94867269 0.94867049 0.9486529\n",
            " 0.94867269 0.94867049        nan        nan        nan 0.94839131\n",
            " 0.94867269 0.94867049 0.9486529  0.94867269 0.94867049        nan\n",
            "        nan        nan 0.94838691 0.94867269 0.94867049 0.9486529\n",
            " 0.94867269 0.94867049        nan        nan        nan 0.94836053\n",
            " 0.94867269 0.94867049 0.9486529  0.94867269 0.94867049        nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#logistic Regression for oversampling:\n",
        "param_grid = {\n",
        "'penalty' : ['l1', 'l2', 'none'],\n",
        "'C' : np.logspace(-4, 4, 20),\n",
        "'solver': ['lbfgs','newton-cg','liblinear'],\n",
        "'max_iter' : [100, 1000]\n",
        "}\n",
        "logcls_os = GridSearchCV(logmodel, param_grid = param_grid, cv = 3, verbose=3, n_jobs=-1)\n",
        "bestlogcls_os = logcls_os.fit(X_train_os, y_train_os)\n",
        "bestlogcls_os.estimator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tXNUUbp4jaeA",
        "outputId": "e6365304-a055-4437-db5a-78e6ebc8b37b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            " [[55535  1407]\n",
            " [ 4484 52300]]\n",
            "\n",
            " Recall: 0.9210340941110172\n",
            "\n",
            " Accuracy Score: 0.9482000597928354\n",
            "\n",
            " Precision Score: 0.9738022976520752\n",
            "\n",
            " F1 Score: 0.9466834402802039\n"
          ]
        }
      ],
      "source": [
        "predict_os = bestlogcls_os.predict(X_test_os)\n",
        "model_performance(y_test_os,predict_os)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNeAZ36KMEbhdoNpKR0vP3a",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}